defaults:
  - dataset: sortable-torch
  - dataloader: sequential-batch
  - record: hifigan
  - clip_gradient: hifigan
  - _self_

dataset:
  train:
    sort_key: waveform

dataloader:
  train:
    batch_size: 16
  validation:
    batch_size: 1

key_mapping:
  train:
    generator:
      input:
        input: log_melspectrogram_slice
      output: estimated_waveform_slice
    discriminator:
      real:
        input:
          input: waveform_slice
        output:
          - - period_real_prob
            - scale_real_prob
          - - period_real_feature_map
            - scale_real_feature_map
      fake:
        input:
          input: ${....generator.output}
        output:
          - - period_fake_prob
            - scale_fake_prob
          - - period_fake_feature_map
            - scale_fake_feature_map
  validation: ${.train}
  inference:
    generator:
      input:
        input: log_melspectrogram
      output: estimated_waveform

resume:
  continue_from:

output:
  exp_dir: "./exp"
  tensorboard_dir: "./tensorboard"
  save_checkpoint:
    iteration:
      every: 200000
      path: ${...exp_dir}/model/hifigan/iteration{iteration}.pth
    epoch:
      every: 1000
      path: ${...exp_dir}/model/hifigan/epoch{epoch}.pth
    last:
      path: ${...exp_dir}/model/hifigan/last.pth
    best_epoch:
      path: ${...exp_dir}/model/hifigan/best_epoch.pth

steps:
  epochs:
  iterations: 1000000
  lr_scheduler:
    generator: epoch
    discriminator: epoch
